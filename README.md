# Awesom-AGI Survey Papers

Must-read Papers on Artifical General Intelligence with foundation models.

---

# üìúContent

- [Awesom-AGI Survey Papers](#awesom-agi-survey-papers)
- [üìúContent](#content)
  - [1. Introduction](#1-introduction)
  - [2. AGI Internal: Unveiling the Mind of AGI](#2-agi-internal-unveiling-the-mind-of-agi)
    - [2.1 Perception](#21-perception)
    - [2.2 Reasoning](#22-reasoning)
    - [2.3 Memory](#23-memory)
    - [2.4 Metacognition](#24-metacognition)
  - [3. AGI Interface: Connecting the World with AGI](#3-agi-interface-connecting-the-world-with-agi)
    - [3.1 Interfaces to Digital World](#31-interfaces-to-digital-world)
    - [3.2 Interfaces to Physical World](#32-interfaces-to-physical-world)
    - [3.3 Interfaces to Intelligence](#33-interfaces-to-intelligence)
      - [3.3.2 Interfaces to Humans](#332-interfaces-to-humans)
  - [4. AGI Systems: Implementing the Mechanism of AGI](#4-agi-systems-implementing-the-mechanism-of-agi)
    - [4.1 System Challenges](#41-system-challenges)
    - [4.2 Scalable Model Architectures](#42-scalable-model-architectures)
    - [4.3 Large-scale Training](#43-large-scale-training)
    - [4.4 Inference Techniques](#44-inference-techniques)
    - [4.5 Cost and Efficiency](#45-cost-and-efficiency)
    - [4.6 Computing Platforms](#46-computing-platforms)
    - [4.7 The Future of AGI Systems](#47-the-future-of-agi-systems)
  - [5. AGI Alignment: Reconciling Needs with AGI](#5-agi-alignment-reconciling-needs-with-agi)
    - [5.1 Expectations of AGI Alignment](#51-expectations-of-agi-alignment)
    - [5.2 AGI Alignment Classifications](#52-agi-alignment-classifications)
    - [5.3 How to Implement: Solutions for Alignment](#53-how-to-implement-solutions-for-alignment)
  - [6. Approach AGI Responsibly](#6-approach-agi-responsibly)
    - [6.1 AI Levels: Charting the Evolution of Artificial Intelligence](#61-ai-levels-charting-the-evolution-of-artificial-intelligence)
      - [6.1.1 AGI Levels](#611-agi-levels)
      - [6.1.2 Constraints and Challenges of Ultimate AGI](#612-constraints-and-challenges-of-ultimate-agi)
      - [6.1.3 How Do We Get to the Next Level of AGI?](#613-how-do-we-get-to-the-next-level-of-agi)
    - [6.2 AGI Evaluation](#62-agi-evaluation)
      - [6.2.1 What Do We Expect from AGI Evaluations](#621-what-do-we-expect-from-agi-evaluations)
      - [6.2.2 Current Evaluation Frameworks and Limitations](#622-current-evaluation-frameworks-and-limitations)
    - [6.3 Potential Ways to Future AGI](#63-potential-ways-to-future-agi)
  - [7. Case Studies](#7-case-studies)
    - [7.1 AI for Science Discovery and Research](#71-ai-for-science-discovery-and-research)
    - [7.2 Generative Visual Intelligence](#72-generative-visual-intelligence)
    - [7.3 World Models](#73-world-models)
    - [7.4 Decentralized LLM](#74-decentralized-llm)
    - [7.5 AI for Coding](#75-ai-for-coding)
    - [7.6 AI for Robotics in Real World Applications](#76-ai-for-robotics-in-real-world-applications)
    - [7.7 Human-AI Collaboration](#77-human-ai-collaboration)
  - [8. Conclusion](#8-conclusion)


## 1. Introduction

## 2. AGI Internal: Unveiling the Mind of AGI
### 2.1 Perception
### 2.2 Reasoning
1. **Chain-of-Thought Prompting Elicits Reasoning in Large Language Models**. *Jason Wei* et al. NeurIPS 2022. [[paper](https://arxiv.org/abs/2201.11903)]
4. **Decomposed Prompting: A Modular Approach for Solving Complex Tasks**. *Tushar Khot* et al. arXiv 2022. [[paper](https://arxiv.org/abs/2210.02406)]
5. **Neural Theory-of-Mind? On the Limits of Social Intelligence in Large LMs**. *Maarten Sap* et al. EMNLP 2022. [[paper](https://arxiv.org/abs/2210.13312)]
6. **Inner Monologue: Embodied Reasoning through Planning with Language Models**. *Wenlong Huang* et al. CoRL 2022. [[paper](https://arxiv.org/abs/2207.05608)]
7. **Survey of Hallucination in Natural Language Generation**. *Ziwei Ji* et al. ACM Computing Surveys 2022. [[paper](https://arxiv.org/abs/2202.03629)]
8. **ReAct: Synergizing Reasoning and Acting in Language Models**. *Shunyu Yao* et al. ICLR 2023. [[paper](https://arxiv.org/abs/2210.03629)]
3. **Complexity-Based Prompting for Multi-Step Reasoning**. *Yao Fu* et al. ICLR 2023. [[paper](https://arxiv.org/abs/2210.00720)]
7. **Towards Reasoning in Large Language Models: A Survey**. *Jie Huang* et al. ACL Findings 2023. [[paper](https://arxiv.org/abs/2212.10403)]
9. **Least-to-Most Prompting Enables Complex Reasoning in Large Language Models**. *Denny Zhou* et al. ICLR 2023. [[paper](https://arxiv.org/abs/2205.10625)]
10. **ProgPrompt: Generating Situated Robot Task Plans using Large Language Models**. *Ishika Singh* et al. ICRA 2023. [[paper](https://arxiv.org/abs/2209.11302)]
11. **Reasoning with Language Model is Planning with World Model**. *Shibo Hao* et al. EMNLP 2023. [[paper](https://arxiv.org/abs/2305.14992)]
12. **Evaluating Object Hallucination in Large Vision-Language Models**. *Yifan Li* et al. EMNLP 2023. [[paper](https://arxiv.org/abs/2305.10355)]
13. **Tree of Thoughts: Deliberate Problem Solving with Large Language Models**. *Shunyu Yao* et al. NeurIPS 2023. [[paper](https://arxiv.org/abs/2305.10601)]
14. **Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents**. *Zihao Wang* et al. NeurIPS 2023. [[paper](https://arxiv.org/abs/2302.01560)]
15. **LLM+P: Empowering Large Language Models with Optimal Planning Proficiency**. *Bo Liu* et al. arXiv 2023. [[paper](https://arxiv.org/abs/2304.11477)]
16. **Language Models, Agent Models, and World Models: The LAW for Machine Reasoning and Planning**. *Zhiting Hu* et al. arXiv 2023. [[paper](https://arxiv.org/abs/2312.05230)]
17. **MMToM-QA: Multimodal Theory of Mind Question Answering**. *Chuanyang Jin* et al. arXiv 2024. [[paper](https://arxiv.org/abs/2401.08743)]
18. **Graph of Thoughts: Solving Elaborate Problems with Large Language Models**. *Maciej Besta* et al. AAAI 2024. [[paper](https://arxiv.org/abs/2308.09687)]

### 2.3 Memory
1. **Dense Passage Retrieval for Open-Domain Question Answering**. *Vladimir Karpukhin* et al. EMNLP 2020. [[paper](https://arxiv.org/abs/2004.04906)]
2. **Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks**. *Patrick Lewis* et al. NeurIPS 2020. [[paper](https://arxiv.org/abs/2005.11401)]
3. **REALM: Retrieval-Augmented Language Model Pre-Training**. *Kelvin Guu* et al. ICML 2020. [[paper](https://arxiv.org/abs/2002.08909)]
4. **Retrieval Augmentation Reduces Hallucination in Conversation**. *Kurt Shuster* et al. EMNLP Findings 2021. [[paper](https://arxiv.org/abs/2104.07567)]
5. **Improving Language Models by Retrieving from Trillions of Tokens**. *Sebastian Borgeaud* et al. ICML 2022. [[paper](https://arxiv.org/abs/2112.04426)]
6. **FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness**. *Tri Dao* et al. NeurIPS 2022. [[paper](https://arxiv.org/abs/2205.14135)]
7. **Generative Agents: Interactive Simulacra of Human Behavior**. *Joon Sung Park* et al. UIST 2023. [[paper](https://arxiv.org/abs/2304.03442)]
8. **Cognitive Architectures for Language Agents**. *Theodore R. Sumers* et al. TMLR 2024. [[paper](https://arxiv.org/abs/2309.02427)]

### 2.4 Metacognition
1. **Evolving Self-supervised Neural Networks: Autonomous Intelligence from Evolved Self-teaching**
   *Nam Le.* arXiv, 2019. [\[eprint\]](https://arxiv.org/abs/1906.08865)

2. **Self-Instruct: Aligning Language Models with Self-Generated Instructions**
   *Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, Hannaneh Hajishirzi.* arXiv, 2022. [\[eprint\]](https://arxiv.org/abs/2212.10560)

3. **ReST meets ReAct: Self-Improvement for Multi-Step Reasoning LLM Agent**
   *Renat Aksitov, Sobhan Miryoosefi, Zonglin Li, Daliang Li, Sheila Babayan, Kavya Kopparapu, Zachary Fisher, Ruiqi Guo, Sushant Prakash, Pranesh Srinivasan, Manzil Zaheer, Felix Yu, Sanjiv Kumar.* arXiv, 2023. [\[eprint\]](https://arxiv.org/abs/2312.10003)

4. **Wizardlm: Empowering large language models to follow complex instructions**
   *Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, Daxin Jiang.* arXiv, 2023. [\[abs\]](https://arxiv.org/abs/2304.12244)

## 3. AGI Interface: Connecting the World with AGI
### 3.1 Interfaces to Digital World
### 3.2 Interfaces to Physical World
### 3.3 Interfaces to Intelligence

#### 3.3.2 Interfaces to Humans

1. **Guidelines for Human-AI Interaction**
   *Saleema Amershi, Dan Weld, Mihaela Vorvoreanu, Adam Fourney, Besmira Nushi, Penny Collisson, Jina Suh, Shamsi Iqbal, Paul N. Bennett, Kori Inkpen, Jaime Teevan, Ruth Kikin-Gil, Eric Horvitz*. CHI 2019. [[paper](https://dl.acm.org/doi/10.1145/3290605.3300233)]

2. **Design Principles for Generative AI Applications**
   *Justin D. Weisz, Jessica He, Michael Muller, Gabriela Hoefer, Rachel Miles, Werner Geyer*. CHI 2024. [[paper](http://arxiv.org/abs/2401.14484)]

3. **Graphologue: Exploring Large Language Model Responses with Interactive Diagrams**
   *Peiling Jiang, Jude Rayan, Steven P. Dow, Haijun Xia*. UIST 2023. [[paper](https://dl.acm.org/doi/10.1145/3586183.3606737)]

4. **Sensecape: Enabling Multilevel Exploration and Sensemaking with Large Language Models**
   *Sangho Suh, Bryan Min, Srishti Palani, Haijun Xia*. UIST 2023. [[paper](https://dl.acm.org/doi/10.1145/3586183.3606756)]

5. **Supporting Sensemaking of Large Language Model Outputs at Scale**
   *Katy Ilonka Gero, Chelse Swoopes, Ziwei Gu, Jonathan K. Kummerfeld, Elena L. Glassman*. CHI 2024. [[paper](https://arxiv.org/abs/2401.13726)]

6. **Luminate: Structured Generation and Exploration of Design Space with Large Language Models for Human-AI Co-Creation**
   *Sangho Suh, Meng Chen, Bryan Min, Toby Jia-Jun Li, Haijun Xia*. CHI 2024. [[Paper](http://arxiv.org/abs/2310.12953)]

7. **AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts**
   *Tongshuang Wu, Michael Terry, Carrie Jun Cai*. CHI 2022. [[Paper](https://dl.acm.org/doi/10.1145/3491102.3517582)]

8. **Promptify: Text-to-Image Generation through Interactive Prompt Exploration with Large Language Models**
   *Stephen Brade, Bryan Wang, Mauricio Sousa, Sageev Oore, Tovi Grossman*. CHI 2023. [[Paper](https://dl.acm.org/doi/10.1145/3586183.3606725)]

9. **ChainForge: A Visual Toolkit for Prompt Engineering and LLM Hypothesis Testing**
   *Ian Arawjo, Chelse Swoopes, Priyan Vaithilingam, Martin Wattenberg, Elena Glassman*. CHI 2024. [[Paper](https://doi.org/10.48550/arXiv.2309.09128)]

10. **CoPrompt: Supporting Prompt Sharing and Referring in Collaborative Natural Language Programming**
    *Li Feng, Ryan Yen, Yuzhe You, Mingming Fan, Jian Zhao, Zhicong Lu*. CHI 2024. [[Paper](http://arxiv.org/abs/2310.09235)]

11. **Generating Automatic Feedback on UI Mockups with Large Language Models**
    *Peitong Duan, Jeremy Warner, Yang Li, Bj√∂rn Hartmann*. CHI 2024. [[Paper](http://arxiv.org/abs/2403.13139)]

12. **Rambler: Supporting Writing With Speech via LLM-Assisted Gist Manipulation**
    *Susan Lin, Jeremy Warner, J. D. Zamfirescu-Pereira, Matthew G. Lee, Sauhard Jain, Michael Xuelin Huang, Piyawat Lertvittayakumjorn, Shanqing Cai, Shumin Zhai, Bj√∂rn Hartmann, Can Liu*. CHI 2024. [[Paper](http://arxiv.org/abs/2401.10838)]

13. **Embedding Large Language Models into Extended Reality: Opportunities and Challenges for Inclusion, Engagement, and Privacy**
    *Efe Bozkir, S√ºleyman √ñzdel, Ka Hei Carrie Lau, Mengdi Wang, Hong Gao, Enkelejda Kasneci*. arXiv 2024. [[Paper](http://arxiv.org/abs/2402.03907)]

14. **GenAssist: Making Image Generation Accessible**
    *Mina Huh, Yi-Hao Peng, Amy Pavel*. UIST 2023. [[Paper](https://dl.acm.org/doi/10.1145/3586183.3606735)]

15. **‚ÄúThe less I type, the better‚Äù: How AI Language Models can Enhance or Impede Communication for AAC Users**
    *Stephanie Valencia, Richard Cave, Krystal Kallarackal, Katie Seaver, Michael Terry, Shaun K. Kane*. CHI 2023. [[Paper](https://dl.acm.org/doi/10.1145/3544548.3581560)]

16. **Re-examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design**
    *Qian Yang, Aaron Steinfeld, Carolyn Ros√©, John Zimmerman*. CHI 2020. [[Paper](https://dl.acm.org/doi/10.1145/3313831.3376301)]

## 4. AGI Systems: Implementing the Mechanism of AGI
### 4.1 System Challenges
### 4.2 Scalable Model Architectures
### 4.3 Large-scale Training
### 4.4 Inference Techniques
### 4.5 Cost and Efficiency
### 4.6 Computing Platforms
### 4.7 The Future of AGI Systems

## 5. AGI Alignment: Reconciling Needs with AGI
### 5.1 Expectations of AGI Alignment
### 5.2 AGI Alignment Classifications
### 5.3 How to Implement: Solutions for Alignment

## 6. Approach AGI Responsibly
### 6.1 AI Levels: Charting the Evolution of Artificial Intelligence
#### 6.1.1 AGI Levels
#### 6.1.2 Constraints and Challenges of Ultimate AGI
#### 6.1.3 How Do We Get to the Next Level of AGI?
### 6.2 AGI Evaluation
#### 6.2.1 What Do We Expect from AGI Evaluations
#### 6.2.2 Current Evaluation Frameworks and Limitations
### 6.3 Potential Ways to Future AGI

## 7. Case Studies
### 7.1 AI for Science Discovery and Research
### 7.2 Generative Visual Intelligence
1. **Deep Unsupervised Learning using Nonequilibrium Thermodynamics**. *Jascha Sohl-Dickstein* et al. ICML 2015. [[paper](https://arxiv.org/abs/1503.03585)]
2. **Generative Modeling by Estimating Gradients of the Data Distribution**. *Yang Song* et al. NeurIPS 2019. [[paper](https://arxiv.org/abs/1907.05600)]
3. **Denoising Diffusion Probabilistic Models**. *Jonathan Ho* et al. NeurIPS 2020. [[paper](https://arxiv.org/abs/2006.11239)]
4. **Score-Based Generative Modeling through Stochastic Differential Equations**. *Yang Song* et al. ICLR 2021. [[paper](https://arxiv.org/abs/2011.13456)]
5. **GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models**. *Alex Nichol* et al. arXiv 2021. [[paper](https://arxiv.org/abs/2112.10741)]
6. **SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations**. *Chenlin Meng* et al. ICLR 2022. [[paper](https://arxiv.org/abs/2108.01073)]
7. **Video Diffusion Models**. *Jonathan Ho* et al. NeurIPS 2022. [[paper](https://arxiv.org/abs/2204.03458)]
8. **Hierarchical Text-Conditional Image Generation with CLIP Latents**. *Aditya Ramesh* et al. arXiv 2022. [[paper](https://arxiv.org/abs/2204.06125)]
9. **Classifier-Free Diffusion Guidance**. *Jonathan Ho* et al. arXiv 2022. [[paper](https://arxiv.org/abs/2207.12598)]
10. **Palette: Image-to-Image Diffusion Models**. *Chitwan Saharia* et al. SIGGRAPH 2022. [[paper](https://arxiv.org/abs/2111.05826)]
11. **High-Resolution Image Synthesis with Latent Diffusion Models**. *Robin Rombach* et al. CVPR 2022. [[paper](https://arxiv.org/abs/2112.10752)]
12. **Adding Conditional Control to Text-to-Image Diffusion Models**. *Lvmin Zhang* et al. ICCV 2023. [[paper](https://arxiv.org/abs/2302.05543)]
13. **Scalable Diffusion Models with Transformers**. *William Peebles* et al. ICCV 2023. [[paper](https://arxiv.org/abs/2212.09748)]
14. **Sequential Modeling Enables Scalable Learning for Large Vision Models**. *Yutong Bai* et al. arXiv 2023. [[paper](https://arxiv.org/abs/2312.00785)]
15. **Video Generation Models as World Simulators**. *Tim Brooks* et al. OpenAI 2024. [[paper](https://openai.com/research/video-generation-models-as-world-simulators)]

### 7.3 World Models
### 7.4 Decentralized LLM
### 7.5 AI for Coding
### 7.6 AI for Robotics in Real World Applications
### 7.7 Human-AI Collaboration

## 8. Conclusion


<!-- ### Agent & Tool:
- [Tool learning with foundation models](https://arxiv.org/pdf/2304.08354.pdf)
- [A Survey on Large Language Model based Autonomous Agents](https://arxiv.org/pdf/2308.11432.pdf)
- [The Rise and Potential of Large Language Model Based Agents: A Survey](https://arxiv.org/pdf/2309.07864.pdf)
- [Cognitive Architectures for Language Agents](https://arxiv.org/pdf/2309.02427.pdf)

### (Multi-Modal) LLM / Foundation Model:
#### LLM
- [A Survey of Large Language Models](https://arxiv.org/pdf/2303.18223.pdf)
- [A Survey on In-context Learning](https://arxiv.org/pdf/2301.00234.pdf)
- [Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond](https://arxiv.org/pdf/2304.13712.pdf)

#### Multi-Modal LLM
- [A Survey on Multimodal Large Language Models](https://arxiv.org/pdf/2306.13549.pdf)

#### General Foundation Model
- [On the Opportunities and Risks of Foundation Models](https://arxiv.org/pdf/2108.07258.pdf)
- [A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT](https://arxiv.org/pdf/2302.09419.pdf)

### Embodied AI:
#### AGI
- [One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era](https://arxiv.org/pdf/2304.06488.pdf)
- [Sparks of Artificial General Intelligence: Early experiments with GPT-4](https://arxiv.org/pdf/2303.12712.pdf)
- [Towards AGI in Computer Vision: Lessons Learned from GPT and Large Language Models](https://arxiv.org/pdf/2306.08641.pdf)
- [A Comprehensive Survey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT](https://arxiv.org/pdf/2303.04226.pdf)

### Github:
- [LLM-Agent-Paper-List](https://github.com/WooooDyy/LLM-Agent-Paper-List) (Agent)
- [Awesome-AI-Agents](https://github.com/e2b-dev/awesome-ai-agents) (Agent)
- [Awesome-Multimodal-Large-Language-Models](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models) (Multi-modal LLM) -->
